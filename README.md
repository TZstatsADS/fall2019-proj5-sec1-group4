# ADS Project 5: Toxic Thread Detector

Term: Fall 2019

+ Team #
+ Projec title: Toxic online comments detector
+ Team members
	+ Xiaotong Li
	+ Runzi Qiang
+ Project summary: We developed a web on a topic of identifing and classifing toxic online comments, the dataset we used are originally from kaggle(https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data). We totally build three models that predicts a probability of each type of toxicity for each comment.
	
**Contribution statement**: ([default](doc/a_note_on_contributions.md)) All team members contributed equally in all stages of this project. All team members approve our work presented in this GitHub repository including this contributions statement. 


__Instruction to open the app__:


Following [suggestions](http://nicercode.github.io/blog/2013-04-05-projects/) by [RICH FITZJOHN](http://nicercode.github.io/about/#Team) (@richfitz). This folder is orgarnized as follows.

```
proj/
├── app/
├────── model/
├────── templates/
├────── static/
├────── venv/
├── data/
├── doc/
└── output/
```

Please see each subfolder for a README file.
